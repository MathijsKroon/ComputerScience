{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install \"textdistance[extras]\"\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import random as rd\n",
    "from random import seed\n",
    "from random import randint\n",
    "from random import choices\n",
    "import itertools\n",
    "import textdistance\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Several small defintions used in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Used to generate the random variables for the hash functions\n",
    "def create_hash_var(num: int): \n",
    "    for i in range(0, num):\n",
    "        xvar = rd.sample(range(1, num+2),num)\n",
    "        yvar = rd.sample(range(0,num+2),num)\n",
    "    return (xvar, yvar)\n",
    "\n",
    "## Both used to calculate the cosine similarity, obtained from:\n",
    "## https://gist.github.com/TamilvananP/002c6532cc3351a55321b5757aa4fcb1\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
    "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "\n",
    "def text_to_vector(text):\n",
    "    WORD = re.compile(r\"\\w+\")\n",
    "    words = WORD.findall(text)\n",
    "    return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TVs-all-merged.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "amount_of_descriptions = 0\n",
    "for key in data.keys():\n",
    "    amount_of_descriptions += len(data[key])\n",
    "\n",
    "new_data = {}\n",
    "i = 1\n",
    "for key in data.keys():\n",
    "    for description in data[key]:\n",
    "        new_data[i] = description\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the title list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(1, len(new_data)+1):\n",
    "     result.append(new_data[i][\"title\"])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the different sets for the 5 bootstraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraplist = []\n",
    "numofbootstraps = 5\n",
    "train = []\n",
    "test = []\n",
    "for i in range(0, numofbootstraps):\n",
    "    bootstrap = rd.choices(range(0,len(result)),k=len(result))\n",
    "    bootstrapnodup = list(dict.fromkeys(bootstrap))\n",
    "    fulllist = list(range(0, len(result)))\n",
    "    train.append(sorted(bootstrapnodup))\n",
    "    testlist = (list(set(fulllist) - set(train[i])))\n",
    "    test.append(testlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSH model for first duplicate matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_model_LSH(train, modelID, modvar):\n",
    "\n",
    "    splittedstring = []\n",
    "    for i in train:\n",
    "        splittedstring.append(result[i].split())\n",
    "    splittedstring\n",
    "\n",
    "    modelIDtrain = []\n",
    "    for i in train:\n",
    "        modelIDtrain.append(modelID[i])\n",
    "    modelIDtrain\n",
    "\n",
    "    testfase = splittedstring\n",
    "\n",
    "    modelwords = []\n",
    "    for i in range(0, len(testfase)):\n",
    "        for j in range(0, len(testfase[i])):\n",
    "            testfase[i][j] = testfase[i][j].replace('-Inch','\"')\n",
    "            testfase[i][j] = testfase[i][j].replace('-inch','\"')\n",
    "            testfase[i][j] = testfase[i][j].replace('inch','\"')\n",
    "            testfase[i][j] = testfase[i][j].replace(' Hz', 'Hz')\n",
    "            testfase[i][j] = testfase[i][j].replace(' hz', 'Hz')\n",
    "            testfase[i][j] = testfase[i][j].replace('hz', 'Hz')\n",
    "            testfase[i][j] = testfase[i][j].replace('hertz', 'Hz')\n",
    "            testfase[i][j] = testfase[i][j].replace('-hz', 'Hz')\n",
    "            testfase[i][j] = testfase[i][j].replace('HZ', 'Hz')\n",
    "            \n",
    "    import re\n",
    "    thesum = 0\n",
    "    regex = re.compile('\\'[@_!#$%^&*<>?/\\|}{~]\\\"')\n",
    "    for i in range(0, len(testfase)):\n",
    "        for j in range(0, len(testfase[i])):\n",
    "            if bool(regex.search(testfase[i][j])):\n",
    "                thesum = thesum + 1\n",
    "            if bool(re.match('[a-zA-Z0-9]', testfase[i][j])):\n",
    "                thesum = thesum + 1\n",
    "            if bool(re.search(\"[0-9]\", testfase[i][j])):\n",
    "                thesum = thesum + 1\n",
    "            if thesum >= 2:\n",
    "                modelwords.append(testfase[i][j])\n",
    "            thesum = 0\n",
    "\n",
    "    regex = re.compile(r'.{3,}\"')\n",
    "    modelwordslsh_final = []\n",
    "    modelwordslsh = [g for g in modelwords if not regex.match(g)]\n",
    "    modelwordslsh_final.append(modelwordslsh)\n",
    "    modelwordscorrect = modelwordslsh_final[0]\n",
    "\n",
    "    mylist = list(dict.fromkeys(modelwordscorrect))\n",
    "\n",
    "    s = (len(mylist),len(modelIDtrain))\n",
    "    A = np.zeros(s)\n",
    "    df = pd.DataFrame(A, index=mylist, columns=modelIDtrain)\n",
    "\n",
    "    testfase2 = testfase\n",
    "    for i in range(0, len(testfase2)):\n",
    "        for j in range(0, len(testfase2[i])):\n",
    "            testfase2[i][j] = testfase2[i][j].replace('#','\"')\n",
    "            testfase2[i][j] = testfase2[i][j].replace('-Inch','\"')\n",
    "            testfase2[i][j] = testfase2[i][j].replace('-inch','\"')\n",
    "            testfase2[i][j] = testfase2[i][j].replace(' inch','\"')\n",
    "            testfase2[i][j] = testfase2[i][j].replace(' Hz', 'Hz')\n",
    "            testfase2[i][j] = testfase2[i][j].replace(' hz', 'Hz')\n",
    "            testfase2[i][j] = testfase2[i][j].replace('hz', 'Hz')\n",
    "            testfase2[i][j] = testfase2[i][j].replace('hertz', 'Hz')\n",
    "            testfase2[i][j] = testfase2[i][j].replace('-hz', 'Hz')\n",
    "            testfase2[i][j] = testfase2[i][j].replace('HZ', 'Hz')\n",
    "    testfase2\n",
    "\n",
    "    s = (len(mylist),len(modelIDtrain))\n",
    "    At = np.zeros(s)\n",
    "    df2 = pd.DataFrame(At, index=mylist, columns=modelIDtrain)\n",
    "    for z in range(0, len(modelIDtrain)):\n",
    "        for j in range(0, len(testfase2[z])):\n",
    "            for i in range(0, len(mylist)):\n",
    "                if testfase2[z][j] == mylist[i]:\n",
    "                    df2.iloc[i,z]= 1\n",
    "\n",
    "    seed(0)\n",
    "    xvar = []\n",
    "    yvar =[]\n",
    "    num_of_hashes = int(len(mylist)/2)-int(len(mylist)/2)%modvar\n",
    "    primes = []\n",
    "    for number in range(num_of_hashes,800):  \n",
    "        if number > 1:  \n",
    "            for i in range(2,number):  \n",
    "                if (number % i) == 0:  \n",
    "                    break  \n",
    "            else:  \n",
    "                primes.append(number)\n",
    "       \n",
    "    randomprime = rd.sample(primes, 1)\n",
    "    mod = randomprime[0]\n",
    "    variables = create_hash_var(num_of_hashes)\n",
    "    hashvalue = [ [ 0 for i in range(len(df2)) ] for j in range(num_of_hashes) ]\n",
    "    for j in range(1, num_of_hashes+1):\n",
    "        for i in range(1,len(df2)):\n",
    "            hashvalue[j-1][i-1] = ((variables[0][j-1]*i+variables[1][j-1])%mod)\n",
    "    final = hashvalue\n",
    "\n",
    "    transposedf2 = df2.transpose()\n",
    "\n",
    "    sig = [float('inf')]*num_of_hashes\n",
    "    signatures = [sig]*(len(transposedf2))\n",
    "    signaturesdf = pd.DataFrame(signatures, index = [modelIDtrain])\n",
    "    signaturesdf.columns = np.arange(1,num_of_hashes+1)\n",
    "\n",
    "    for i in range(0,len(transposedf2)): ## i is for the rows (modelID)\n",
    "        for j in range(0, len(transposedf2.iloc[0])): ## j is for the columns (model words)\n",
    "            if transposedf2.iloc[i,j] == 1: ## check for the first tv, than for the model words if it is present\n",
    "                for z in range(0, len(final)): ## check for the different hashes\n",
    "                    if final[z][j] < signaturesdf.iloc[i,z]: ## if value per hash, per e\n",
    "                        signaturesdf.iloc[i,z] = final[z][j]                    \n",
    "\n",
    "    signaturesdft = signaturesdf.transpose()\n",
    "\n",
    "    bandlength = modvar\n",
    "    amountofbandths = num_of_hashes/bandlength\n",
    "    signaturesperbandth = [];\n",
    "    for i in range(1, int(amountofbandths)+1):\n",
    "            if i == 1:\n",
    "                signaturesperbandth.append(signaturesdft.iloc[0:bandlength].astype(int))\n",
    "            else:\n",
    "                signaturesperbandth.append(signaturesdft.iloc[bandlength*(i-1):bandlength*(i)].astype(int))\n",
    "\n",
    "    matrixwithkeyssize = (len(signaturesperbandth),len(modelIDtrain))\n",
    "    matrixwithkeys = np.zeros(matrixwithkeyssize)\n",
    "    allkeys = pd.DataFrame(matrixwithkeys, columns=modelIDtrain)\n",
    "\n",
    "    string = ''\n",
    "    for b in range(0, len(signaturesperbandth)):\n",
    "        for j in range(0, len(signaturesperbandth[b].iloc[0])):\n",
    "            for i in range(0, len(signaturesperbandth[0])):\n",
    "                string = string + str(signaturesperbandth[b].iloc[i,j])\n",
    "            allkeys.iloc[b,j] = string\n",
    "            string = ''\n",
    "\n",
    "    tvlist = [\"tv\" + str(i) for i in train]\n",
    "\n",
    "    sizekeys = (len(allkeys.iloc[0]),len(allkeys))\n",
    "    sizething = np.zeros(sizekeys)\n",
    "    allkeyspertv = pd.DataFrame(sizething, index=modelIDtrain)\n",
    "\n",
    "    tvlength = (len(tvlist),len(tvlist))\n",
    "    Atvlength = np.zeros(tvlength)\n",
    "    dftvlist = pd.DataFrame(Atvlength, index=tvlist, columns=tvlist)\n",
    "    dftvlistint = dftvlist.astype(int)\n",
    "\n",
    "    for i in range(0, len(allkeys)):\n",
    "        allkeysperband = pd.DataFrame(allkeys.iloc[i,:])\n",
    "        allkeysperband.reset_index(drop=True)\n",
    "        allkeysperband.index = tvlist\n",
    "        sortedkeypertv = allkeysperband.sort_values(i)\n",
    "\n",
    "        masterlist = [];\n",
    "        smallerlist = [];\n",
    "        for j in range(0, len(sortedkeypertv)-1):\n",
    "            if j == (len(sortedkeypertv)-2):\n",
    "                smallerlist.append(str(sortedkeypertv.index[j]))\n",
    "                smallerlist.append(str(sortedkeypertv.index[j+1]))\n",
    "                masterlist.append(smallerlist)\n",
    "            elif sortedkeypertv[i][j+1] == sortedkeypertv[i][j]:\n",
    "                smallerlist.append(str(sortedkeypertv.index[j]))\n",
    "            else:\n",
    "                smallerlist.append(str(sortedkeypertv.index[j]))\n",
    "                masterlist.append(smallerlist)\n",
    "                smallerlist = []\n",
    "\n",
    "        listofcombos = []\n",
    "        for z in range(0, len(masterlist)):\n",
    "            for subset in itertools.combinations(masterlist[z], 2):\n",
    "                listofcombos.append(subset)\n",
    "\n",
    "        for p in range(0,len(listofcombos)):\n",
    "            dftvlistint[listofcombos[p][0]][listofcombos[p][1]] = 1\n",
    "            dftvlistint[listofcombos[p][1]][listofcombos[p][0]] = 1\n",
    "    \n",
    "    ## Now LSH is finished\n",
    "    arrdata = dftvlistint.to_numpy()\n",
    "    newarrdata = np.triu(arrdata)\n",
    "    dfnew = pd.DataFrame(newarrdata)\n",
    "    \n",
    "    #All comparisons made from candidate pairs\n",
    "    numofcomp2 = dfnew\n",
    "    numofcomp2 = numofcomp2.replace(float('-inf'),0)\n",
    "    numberofcomparisons2 = sum(numofcomp2[numofcomp2 > 0].count())\n",
    "    \n",
    "    ## All comparisons possible\n",
    "    onematrixl = (len(dftvlistint), len(dftvlistint))\n",
    "    onematrix = np.ones(onematrixl)\n",
    "    onematrixup = np.triu(onematrix)\n",
    "    np.fill_diagonal(onematrixup, 0)\n",
    "    onematrixupdf = pd.DataFrame(onematrixup)\n",
    "    numofonesindf = sum(onematrixupdf[onematrixupdf > 0].count())\n",
    "    \n",
    "    fracofcomparisons = numberofcomparisons2/numofonesindf\n",
    "    \n",
    "    modelwordsperlist = []\n",
    "    for i in range(0, len(testfase)):\n",
    "        for j in range(0, len(testfase[i])):\n",
    "            if bool(regex.search(testfase[i][j])):\n",
    "                thesum = thesum + 1\n",
    "            if bool(re.match('[a-zA-Z0-9]', testfase[i][j])):\n",
    "                thesum = thesum + 1\n",
    "            if bool(re.search(\"[0-9]\", testfase[i][j])):\n",
    "                thesum = thesum + 1\n",
    "            if thesum >= 2:\n",
    "                modelwordsperlist.append(testfase[i][j])\n",
    "            thesum = 0\n",
    "        modelwords.insert(i,modelwordsperlist)\n",
    "        modelwordsperlist = []\n",
    "\n",
    "    regex = re.compile(r'.{3,}\"')\n",
    "    modelwordscleaned_final = []\n",
    "    for i in range(0, len(modelwords)):\n",
    "        modelwordsclean = [g for g in modelwords[i] if not regex.match(g)]\n",
    "        modelwordscleaned_final.append(modelwordsclean)\n",
    "    \n",
    "    shops = []\n",
    "    for i in train:\n",
    "         shops.append(new_data[i+1][\"shop\"])\n",
    "    \n",
    "    brands = []\n",
    "    for i in train:\n",
    "        if ('Brand' in new_data[i+1]['featuresMap']):\n",
    "            brands.append(new_data[i+1]['featuresMap']['Brand'])\n",
    "        elif ('Brand Name' in new_data[i+1]['featuresMap']):\n",
    "            brands.append(new_data[i+1]['featuresMap']['Brand Name'])\n",
    "        else:\n",
    "            brands.append('No brand')\n",
    "\n",
    "    tvlength = (len(tvlist),len(tvlist))\n",
    "    Atvlength = np.zeros(tvlength)\n",
    "    dftvlist = pd.DataFrame(Atvlength, index=tvlist, columns=tvlist )\n",
    "    dftvlist\n",
    "    \n",
    "    modelID_current = []\n",
    "    for i in train:\n",
    "        modelID_current.append(new_data[i+1][\"title\"])\n",
    "\n",
    "    for i in range(0, len(train)):\n",
    "        for j in range(0, len(train)):\n",
    "            if j > i:\n",
    "                if dfnew.iloc[i,j] == 1:\n",
    "                    dftvlist.iloc[i,j] = get_cosine(text_to_vector(modelID_current[i]), text_to_vector(modelID_current[j]))\n",
    "    \n",
    "    for i in range(0, len(dftvlist)):\n",
    "        for j in range(0, len(dftvlist)):\n",
    "            if j > i and shops[i] == shops[j]:\n",
    "                dftvlist.iloc[i,j] = -float('inf')\n",
    "            if j > i and brands[i] != brands[j] and brands[i] != 'No brand' and brands[j] != 'No brand':\n",
    "                dftvlist.iloc[i,j] = -float('inf')\n",
    "                \n",
    "    ## All comparisons, with shops and brands taken into account with LSH\n",
    "    numofcomp = dftvlist\n",
    "    numofcomp = numofcomp.replace(float('-inf'),0)\n",
    "    numberofcomparisons = sum(numofcomp[numofcomp > 0].count())\n",
    "    \n",
    "    ## All possible comparisons, with shops and brands taken into account\n",
    "    onematrix2 = (len(dftvlistint), len(dftvlistint))\n",
    "    onematrix3 = np.ones(onematrix2)\n",
    "    onematrixup2 = np.triu(onematrix3)\n",
    "    np.fill_diagonal(onematrixup2, 0)\n",
    "    onematrixupdf2 = pd.DataFrame(onematrixup2)\n",
    "    for i in range(0, len(onematrixupdf2)):\n",
    "        for j in range(0, len(onematrixupdf2)):\n",
    "            if j > i and shops[i] == shops[j]:\n",
    "                onematrixupdf2.iloc[i,j] = 0\n",
    "            if j > i and brands[i] != brands[j] and brands[i] != 'No brand' and brands[j] != 'No brand':\n",
    "                onematrixupdf2.iloc[i,j] = 0\n",
    "    numofonesindf4 = sum(onematrixupdf[onematrixupdf2 > 0].count())\n",
    "    \n",
    "    fracofcomparisons2 = numberofcomparisons/numofonesindf4\n",
    "    \n",
    "    originalm = (len(modelIDtrain),len(modelIDtrain))\n",
    "    originalA = np.zeros(originalm)\n",
    "    originalcorrect = pd.DataFrame(originalA, index=modelIDtrain, columns=modelIDtrain)\n",
    "    for i in range(0, len(modelIDtrain)):\n",
    "        for j in range(0, len(modelIDtrain)):\n",
    "            if modelIDtrain[i] == modelIDtrain[j]:\n",
    "                originalcorrect.iloc[i,j] = 1\n",
    "    originalcorrect.values[[np.arange(originalcorrect.shape[0])]*2] = 0\n",
    "\n",
    "    falsenegativesLSH = 0\n",
    "    falsepositivesLSH = 0\n",
    "    truenegativesLSH = 0\n",
    "    truepositivesLSH = 0\n",
    "\n",
    "    for i in range(0, len(originalcorrect)):\n",
    "        for j in range(0, len(originalcorrect)):\n",
    "            if j > i:\n",
    "                if  dfnew.iloc[i,j] == 0 and originalcorrect.iloc[i,j] == 0:\n",
    "                    truenegativesLSH = truenegativesLSH + 1\n",
    "                elif  dfnew.iloc[i,j] == 0 and originalcorrect.iloc[i,j] == 1:\n",
    "                    falsenegativesLSH = falsenegativesLSH + 1\n",
    "                elif  dfnew.iloc[i,j] == 1 and originalcorrect.iloc[i,j] == 0:\n",
    "                    falsepositivesLSH = falsepositivesLSH + 1\n",
    "                elif  dfnew.iloc[i,j] == 1 and originalcorrect.iloc[i,j] == 1:\n",
    "                    truepositivesLSH = truepositivesLSH + 1\n",
    "\n",
    "    f1measureLSH = (truepositivesLSH/(truepositivesLSH+0.5*(falsenegativesLSH+falsepositivesLSH)))\n",
    "    pairqualityLSH = (truepositivesLSH)/(numberofcomparisons) \n",
    "    paircompletenessLSH = (truepositivesLSH)/(truepositivesLSH + falsenegativesLSH)\n",
    "    f1starmeasureLSH = (2*pairqualityLSH*paircompletenessLSH)/(pairqualityLSH+paircompletenessLSH)\n",
    "    \n",
    "    return (fracofcomparisons, fracofcomparisons2, f1starmeasureLSH, f1measureLSH, truepositivesLSH, falsepositivesLSH, falsenegativesLSH, truenegativesLSH, pairqualityLSH, paircompletenessLSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = []\n",
    "points = [1, 3 , 4, 5, 7, 10, 14]\n",
    "for i in points:\n",
    "    for j in range(0, 5):\n",
    "        outcome_tuple = full_model_LSH(test[j], modelID, i)\n",
    "        outcomes.append(outcome_tuple)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_f1star = []\n",
    "avg_fracofcomp =[]\n",
    "avg_paircomplete = []\n",
    "avg_pairqual= []\n",
    "currentavgf1star = 0\n",
    "currentfracofcomp = 0\n",
    "currentpaircomp = 0\n",
    "currentpairqual = 0\n",
    "iterations = [0,5,10,15,20,25,30]\n",
    "for i in iterations:\n",
    "    currentavgf1star = outcomes[i][2]+outcomes[i+1][2]+outcomes[i+2][2]+outcomes[i+3][2]+outcomes[i+4][2]\n",
    "    avg_f1star.append(currentavgf1star/5)\n",
    "    \n",
    "    currentfracofcomp = outcomes[i][0]+outcomes[i+1][0]+outcomes[i+2][0]+outcomes[i+3][0]+outcomes[i+4][0]\n",
    "    avg_fracofcomp.append(currentfracofcomp/5)\n",
    "    \n",
    "    currentpaircomp = outcomes[i][9]+outcomes[i+1][9]+outcomes[i+2][9]+outcomes[i+3][9]+outcomes[i+4][9]\n",
    "    avg_paircomplete.append(currentpaircomp/5)\n",
    "    \n",
    "    currentpairqual = outcomes[i][8]+outcomes[i+1][8]+outcomes[i+2][8]+outcomes[i+3][8]+outcomes[i+4][8]\n",
    "    avg_pairqual.append(currentpairqual/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_fracofcomp, avg_paircomplete, 'k')\n",
    "plt.xlim(0,0.6)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Fraction of comparisons')\n",
    "plt.ylabel('Pair completeness')\n",
    "plt.savefig('fig1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_fracofcomp, avg_pairqual, 'k')\n",
    "plt.xlim(0,0.6)\n",
    "plt.ylim(0,0.2)\n",
    "plt.xlabel('Fraction of comparisons')\n",
    "plt.ylabel('Pair quality')\n",
    "plt.savefig('fig2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_fracofcomp, avg_f1star, 'k')\n",
    "plt.xlim(0,0.6)\n",
    "plt.ylim(0,0.2)\n",
    "plt.xlabel('Fraction of comparisons')\n",
    "plt.ylabel('$F_{1}^*$-measure')\n",
    "plt.savefig('fig3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the full model including the Title Model Words Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_model(train, beta, delta, gamma, modelID, modvar,param_cluster):\n",
    "    \n",
    "    splittedstring = []\n",
    "    for i in train:\n",
    "        splittedstring.append(result[i].split())\n",
    "    splittedstring\n",
    "\n",
    "    modelIDtrain = []\n",
    "    for i in train:\n",
    "        modelIDtrain.append(modelID[i])\n",
    "    modelIDtrain\n",
    "\n",
    "    testfase = splittedstring\n",
    "    \n",
    "    ## Cleaning the data\n",
    "    modelwords = []\n",
    "    for i in range(0, len(testfase)):\n",
    "        for j in range(0, len(testfase[i])):\n",
    "            testfase[i][j] = testfase[i][j].replace('-Inch','\"')\n",
    "            testfase[i][j] = testfase[i][j].replace('-inch','\"')\n",
    "            testfase[i][j] = testfase[i][j].replace('inch','\"')\n",
    "            testfase[i][j] = testfase[i][j].replace(' Hz', 'Hz')\n",
    "            testfase[i][j] = testfase[i][j].replace(' hz', 'Hz')\n",
    "            testfase[i][j] = testfase[i][j].replace('hz', 'Hz')\n",
    "            testfase[i][j] = testfase[i][j].replace('hertz', 'Hz')\n",
    "            testfase[i][j] = testfase[i][j].replace('-hz', 'Hz')\n",
    "            testfase[i][j] = testfase[i][j].replace('HZ', 'Hz')\n",
    "    import re\n",
    "    thesum = 0\n",
    "    regex = re.compile('\\'[@_!#$%^&*<>?/\\|}{~]\\\"')\n",
    "    for i in range(0, len(testfase)):\n",
    "        for j in range(0, len(testfase[i])):\n",
    "            if bool(regex.search(testfase[i][j])):\n",
    "                thesum = thesum + 1\n",
    "            if bool(re.match('[a-zA-Z0-9]', testfase[i][j])):\n",
    "                thesum = thesum + 1\n",
    "            if bool(re.search(\"[0-9]\", testfase[i][j])):\n",
    "                thesum = thesum + 1\n",
    "            if thesum >= 2:\n",
    "                modelwords.append(testfase[i][j])\n",
    "            thesum = 0\n",
    "\n",
    "    regex = re.compile(r'.{3,}\"')\n",
    "    modelwordslsh_final = []\n",
    "    modelwordslsh = [g for g in modelwords if not regex.match(g)]\n",
    "    modelwordslsh_final.append(modelwordslsh)\n",
    "    modelwordscorrect = modelwordslsh_final[0]\n",
    "\n",
    "    mylist = list(dict.fromkeys(modelwordscorrect))\n",
    "\n",
    "    s = (len(mylist),len(modelIDtrain))\n",
    "    A = np.zeros(s)\n",
    "    df = pd.DataFrame(A, index=mylist, columns=modelIDtrain)\n",
    "\n",
    "    testfase2 = testfase\n",
    "    for i in range(0, len(testfase2)):\n",
    "        for j in range(0, len(testfase2[i])):\n",
    "            testfase2[i][j] = testfase2[i][j].replace('#','\"')\n",
    "            testfase2[i][j] = testfase2[i][j].replace('-Inch','\"')\n",
    "            testfase2[i][j] = testfase2[i][j].replace('-inch','\"')\n",
    "            testfase2[i][j] = testfase2[i][j].replace(' inch','\"')\n",
    "            testfase2[i][j] = testfase2[i][j].replace(' Hz', 'Hz')\n",
    "            testfase2[i][j] = testfase2[i][j].replace(' hz', 'Hz')\n",
    "            testfase2[i][j] = testfase2[i][j].replace('hz', 'Hz')\n",
    "            testfase2[i][j] = testfase2[i][j].replace('hertz', 'Hz')\n",
    "            testfase2[i][j] = testfase2[i][j].replace('-hz', 'Hz')\n",
    "            testfase2[i][j] = testfase2[i][j].replace('HZ', 'Hz')\n",
    "    testfase2\n",
    "\n",
    "    s = (len(mylist),len(modelIDtrain))\n",
    "    At = np.zeros(s)\n",
    "    df2 = pd.DataFrame(At, index=mylist, columns=modelIDtrain)\n",
    "    for z in range(0, len(modelIDtrain)):\n",
    "        for j in range(0, len(testfase2[z])):\n",
    "            for i in range(0, len(mylist)):\n",
    "                if testfase2[z][j] == mylist[i]:\n",
    "                    df2.iloc[i,z]= 1\n",
    "                                   \n",
    "    ## Creating the random hashes\n",
    "    seed(0)\n",
    "    xvar = []\n",
    "    yvar =[]\n",
    "    num_of_hashes = int(len(mylist)/2)-int(len(mylist)/2)%modvar\n",
    "    primes = []\n",
    "    for number in range(num_of_hashes,800):  \n",
    "        if number > 1:  \n",
    "            for i in range(2,number):  \n",
    "                if (number % i) == 0:  \n",
    "                    break  \n",
    "            else:  \n",
    "                primes.append(number)\n",
    "       \n",
    "    randomprime = rd.sample(primes, 1)\n",
    "    mod = randomprime[0]\n",
    "    variables = create_hash_var(num_of_hashes)\n",
    "    hashvalue = [ [ 0 for i in range(len(df2)) ] for j in range(num_of_hashes) ]\n",
    "    for j in range(1, num_of_hashes+1):\n",
    "        for i in range(1,len(df2)):\n",
    "            hashvalue[j-1][i-1] = ((variables[0][j-1]*i+variables[1][j-1])%mod)\n",
    "    final = hashvalue\n",
    "\n",
    "    transposedf2 = df2.transpose()\n",
    "    \n",
    "    ## Creating the signatures\n",
    "    sig = [float('inf')]*num_of_hashes\n",
    "    signatures = [sig]*(len(transposedf2))\n",
    "    signaturesdf = pd.DataFrame(signatures, index = [modelIDtrain])\n",
    "    signaturesdf.columns = np.arange(1,num_of_hashes+1)\n",
    "\n",
    "    for i in range(0,len(transposedf2)): ## i is for the rows (modelID)\n",
    "        for j in range(0, len(transposedf2.iloc[0])): ## j is for the columns (model words)\n",
    "            if transposedf2.iloc[i,j] == 1: ## check for the first tv, than for the model words if it is present\n",
    "                for z in range(0, len(final)): ## check for the different hashes\n",
    "                    if final[z][j] < signaturesdf.iloc[i,z]: ## if value per hash, per e\n",
    "                        signaturesdf.iloc[i,z] = final[z][j]                    \n",
    "\n",
    "    signaturesdft = signaturesdf.transpose()\n",
    "\n",
    "    bandlength = modvar\n",
    "    amountofbandths = num_of_hashes/bandlength\n",
    "    signaturesperbandth = [];\n",
    "    for i in range(1, int(amountofbandths)+1):\n",
    "            if i == 1:\n",
    "                signaturesperbandth.append(signaturesdft.iloc[0:bandlength].astype(int))\n",
    "            else:\n",
    "                signaturesperbandth.append(signaturesdft.iloc[bandlength*(i-1):bandlength*(i)].astype(int))\n",
    "\n",
    "    matrixwithkeyssize = (len(signaturesperbandth),len(modelIDtrain))\n",
    "    matrixwithkeys = np.zeros(matrixwithkeyssize)\n",
    "    allkeys = pd.DataFrame(matrixwithkeys, columns=modelIDtrain)\n",
    "\n",
    "    string = ''\n",
    "    for b in range(0, len(signaturesperbandth)):\n",
    "        for j in range(0, len(signaturesperbandth[b].iloc[0])):\n",
    "            for i in range(0, len(signaturesperbandth[0])):\n",
    "                string = string + str(signaturesperbandth[b].iloc[i,j])\n",
    "            allkeys.iloc[b,j] = string\n",
    "            string = ''\n",
    "\n",
    "    tvlist = [\"tv\" + str(i) for i in train]\n",
    "\n",
    "    sizekeys = (len(allkeys.iloc[0]),len(allkeys))\n",
    "    sizething = np.zeros(sizekeys)\n",
    "    allkeyspertv = pd.DataFrame(sizething, index=modelIDtrain)\n",
    "\n",
    "    tvlength = (len(tvlist),len(tvlist))\n",
    "    Atvlength = np.zeros(tvlength)\n",
    "    dftvlist = pd.DataFrame(Atvlength, index=tvlist, columns=tvlist)\n",
    "    dftvlistint = dftvlist.astype(int)\n",
    "    \n",
    "    ## All of the candidate duplicates are put into a matrix\n",
    "    for i in range(0, len(allkeys)):\n",
    "        allkeysperband = pd.DataFrame(allkeys.iloc[i,:])\n",
    "        allkeysperband.reset_index(drop=True)\n",
    "        allkeysperband.index = tvlist\n",
    "        sortedkeypertv = allkeysperband.sort_values(i)\n",
    "\n",
    "        masterlist = [];\n",
    "        smallerlist = [];\n",
    "        for j in range(0, len(sortedkeypertv)-1):\n",
    "            if j == (len(sortedkeypertv)-2):\n",
    "                smallerlist.append(str(sortedkeypertv.index[j]))\n",
    "                smallerlist.append(str(sortedkeypertv.index[j+1]))\n",
    "                masterlist.append(smallerlist)\n",
    "            elif sortedkeypertv[i][j+1] == sortedkeypertv[i][j]:\n",
    "                smallerlist.append(str(sortedkeypertv.index[j]))\n",
    "            else:\n",
    "                smallerlist.append(str(sortedkeypertv.index[j]))\n",
    "                masterlist.append(smallerlist)\n",
    "                smallerlist = []\n",
    "\n",
    "        listofcombos = []\n",
    "        for z in range(0, len(masterlist)):\n",
    "            for subset in itertools.combinations(masterlist[z], 2):\n",
    "                listofcombos.append(subset)\n",
    "\n",
    "        for p in range(0,len(listofcombos)):\n",
    "            dftvlistint[listofcombos[p][0]][listofcombos[p][1]] = 1\n",
    "            dftvlistint[listofcombos[p][1]][listofcombos[p][0]] = 1\n",
    "    \n",
    "    arrdata = dftvlistint.to_numpy()\n",
    "    newarrdata = np.triu(arrdata)\n",
    "    dfnew = pd.DataFrame(newarrdata)\n",
    "    \n",
    "    #All comparisons made from candidate pairs\n",
    "    numofcomp2 = dfnew\n",
    "    numofcomp2 = numofcomp2.replace(float('-inf'),0)\n",
    "    numberofcomparisons2 = sum(numofcomp2[numofcomp2 > 0].count())\n",
    "    \n",
    "    ## All comparisons possible\n",
    "    onematrixl = (len(dftvlistint), len(dftvlistint))\n",
    "    onematrix = np.ones(onematrixl)\n",
    "    onematrixup = np.triu(onematrix)\n",
    "    np.fill_diagonal(onematrixup, 0)\n",
    "    onematrixupdf = pd.DataFrame(onematrixup)\n",
    "    numofonesindf = sum(onematrixupdf[onematrixupdf > 0].count())\n",
    "    \n",
    "    fracofcomparisons = numberofcomparisons2/numofonesindf\n",
    "    \n",
    "    modelwordsperlist = []\n",
    "    for i in range(0, len(testfase)):\n",
    "        for j in range(0, len(testfase[i])):\n",
    "            if bool(regex.search(testfase[i][j])):\n",
    "                thesum = thesum + 1\n",
    "            if bool(re.match('[a-zA-Z0-9]', testfase[i][j])):\n",
    "                thesum = thesum + 1\n",
    "            if bool(re.search(\"[0-9]\", testfase[i][j])):\n",
    "                thesum = thesum + 1\n",
    "            if thesum >= 2:\n",
    "                modelwordsperlist.append(testfase[i][j])\n",
    "            thesum = 0\n",
    "        modelwords.insert(i,modelwordsperlist)\n",
    "        modelwordsperlist = []\n",
    "\n",
    "    regex = re.compile(r'.{3,}\"')\n",
    "    modelwordscleaned_final = []\n",
    "    for i in range(0, len(modelwords)):\n",
    "        modelwordsclean = [g for g in modelwords[i] if not regex.match(g)]\n",
    "        modelwordscleaned_final.append(modelwordsclean)\n",
    "    \n",
    "    shops = []\n",
    "    for i in train:\n",
    "         shops.append(new_data[i+1][\"shop\"])\n",
    "    \n",
    "    brands = []\n",
    "    for i in train:\n",
    "        if ('Brand' in new_data[i+1]['featuresMap']):\n",
    "            brands.append(new_data[i+1]['featuresMap']['Brand'])\n",
    "        elif ('Brand Name' in new_data[i+1]['featuresMap']):\n",
    "            brands.append(new_data[i+1]['featuresMap']['Brand Name'])\n",
    "        else:\n",
    "            brands.append('No brand')\n",
    "\n",
    "    tvlength = (len(tvlist),len(tvlist))\n",
    "    Atvlength = np.zeros(tvlength)\n",
    "    dftvlist = pd.DataFrame(Atvlength, index=tvlist, columns=tvlist )\n",
    "    dftvlist\n",
    "    \n",
    "    modelID_current = []\n",
    "    for i in train:\n",
    "        modelID_current.append(new_data[i+1][\"title\"])\n",
    "\n",
    "    for i in range(0, len(train)):\n",
    "        for j in range(0, len(train)):\n",
    "            if j > i:\n",
    "                if dfnew.iloc[i,j] == 1:\n",
    "                    dftvlist.iloc[i,j] = get_cosine(text_to_vector(modelID_current[i]), text_to_vector(modelID_current[j]))\n",
    "    \n",
    "    for i in range(0, len(dftvlist)):\n",
    "        for j in range(0, len(dftvlist)):\n",
    "            if j > i and shops[i] == shops[j]:\n",
    "                dftvlist.iloc[i,j] = -float('inf')\n",
    "            if j > i and brands[i] != brands[j] and brands[i] != 'No brand' and brands[j] != 'No brand':\n",
    "                dftvlist.iloc[i,j] = -float('inf')\n",
    "                \n",
    "    ## All comparisons, with shops and brands taken into account with LSH\n",
    "    numofcomp = dftvlist\n",
    "    numofcomp = numofcomp.replace(float('-inf'),0)\n",
    "    numberofcomparisons = sum(numofcomp[numofcomp > 0].count())\n",
    "    \n",
    "    ## All possible comparisons, with shops and brands taken into account\n",
    "    onematrix2 = (len(dftvlistint), len(dftvlistint))\n",
    "    onematrix3 = np.ones(onematrix2)\n",
    "    onematrixup2 = np.triu(onematrix3)\n",
    "    np.fill_diagonal(onematrixup2, 0)\n",
    "    onematrixupdf2 = pd.DataFrame(onematrixup2)\n",
    "    for i in range(0, len(onematrixupdf2)):\n",
    "        for j in range(0, len(onematrixupdf2)):\n",
    "            if j > i and shops[i] == shops[j]:\n",
    "                onematrixupdf2.iloc[i,j] = 0\n",
    "            if j > i and brands[i] != brands[j] and brands[i] != 'No brand' and brands[j] != 'No brand':\n",
    "                onematrixupdf2.iloc[i,j] = 0\n",
    "    numofonesindf4 = sum(onematrixupdf[onematrixupdf2 > 0].count())\n",
    "    \n",
    "    fracofcomparisons2 = numberofcomparisons/numofonesindf4\n",
    "    \n",
    "    tvlength = (len(tvlist),len(tvlist))\n",
    "    Atvlength = np.zeros(tvlength)\n",
    "    dfsimlev = pd.DataFrame(Atvlength)\n",
    "\n",
    "    tvlength1 = (len(tvlist),len(tvlist))\n",
    "    Atvlength1 = np.zeros(tvlength1)\n",
    "    dfsimlevMW = pd.DataFrame(Atvlength1)\n",
    "\n",
    "    list1=[]\n",
    "    regex = re.compile(r'[0-9]*')\n",
    "    for i in range(0, len(modelwordscleaned_final)):\n",
    "        list2 = [re.sub(r'[0-9]*', '', item) for item in modelwordscleaned_final[i]]\n",
    "        list1.append(list2)\n",
    "\n",
    "    list3=[]\n",
    "    regex = re.compile(r'[^0-9]*')\n",
    "    for i in range(0, len(modelwordscleaned_final)):\n",
    "        list4 = [re.sub(r'[^0-9]*', '', item) for item in modelwordscleaned_final[i]]\n",
    "        list3.append(list4)\n",
    "\n",
    "   ## Start of Title Model Words Method\n",
    "    sum_lev_MW = 0\n",
    "    sum_lev = 0\n",
    "    sum_length = 0\n",
    "    sum_length_allpairs = 0\n",
    "    for i in range(0, len(dftvlist)):\n",
    "        for j in range(0, len(dftvlist)):\n",
    "            if j > i and dfnew.iloc[i,j] == 1 and dftvlist.iloc[i,j] < gamma and dftvlist.iloc[i,j] >= 0:\n",
    "                for z in range(0, len(modelwordscleaned_final[i])):\n",
    "                    for x in range(0, len(modelwordscleaned_final[j])):\n",
    "                        first_model = list1[i][z]\n",
    "                        second_model = list1[j][x]\n",
    "                        text_distance = textdistance.levenshtein.normalized_distance(first_model, second_model)\n",
    "                        first_item = modelwordscleaned_final[i][z]\n",
    "                        second_item = modelwordscleaned_final[j][x]\n",
    "                        total_distance = textdistance.levenshtein.normalized_distance(first_item, second_item)\n",
    "                        length_allpairs = len(modelwordscleaned_final[i][z])+len(modelwordscleaned_final[j][x])\n",
    "                        sum_lev = sum_lev + (1-total_distance) * length_allpairs\n",
    "                        sum_length_allpairs = sum_length_allpairs + length_allpairs\n",
    "                        if text_distance < 0.1:\n",
    "                            first_word = list3[i][z]\n",
    "                            second_word = list3[j][x]\n",
    "                            numeric_distance = textdistance.levenshtein.normalized_distance(first_word, second_word)\n",
    "                            if numeric_distance > 0:\n",
    "                                dftvlist.iloc[i,j] = -float('inf')\n",
    "                                length = len(modelwordscleaned_final[i][z])+len(modelwordscleaned_final[j][x])\n",
    "                                sum_length = sum_length + length\n",
    "                            else:\n",
    "                                first_string = modelwordscleaned_final[i][z]\n",
    "                                second_string = modelwordscleaned_final[j][x]\n",
    "                                string_distance = textdistance.levenshtein.normalized_distance(first_string, second_string)\n",
    "                                length = len(modelwordscleaned_final[i][z])+len(modelwordscleaned_final[j][x])\n",
    "                                sum_lev_MW = sum_lev_MW + (1-string_distance) * length\n",
    "                                sum_length = sum_length + length\n",
    "            if dftvlist.iloc[i,j] != 0 and sum_length != 0:\n",
    "                avg_lev = sum_lev / sum_length_allpairs\n",
    "                avg_lev_MW = sum_lev_MW / sum_length\n",
    "                dfsimlev.iloc[i,j] = beta * dftvlist.iloc[i,j] + (1-beta) * avg_lev\n",
    "                dfsimlevMW.iloc[i,j] = delta * avg_lev_MW + (1-delta) * dfsimlev.iloc[i,j]\n",
    "                sum_lev_MW = 0\n",
    "                sum_length = 0\n",
    "                sum_lev = 0\n",
    "                sum_length_allpairs = 0\n",
    "\n",
    "    for i in range(0, len(dfsimlevMW)):\n",
    "        for j in range(0, len(dfsimlevMW)):\n",
    "            if j > i and shops[i] == shops[j]:\n",
    "                dfsimlevMW.iloc[i,j] = -float('inf')\n",
    "            if j > i and brands[i] != brands[j] and brands[i] != 'No brand' and brands[j] != 'No brand':\n",
    "                dfsimlevMW.iloc[i,j] = -float('inf')\n",
    "\n",
    "    finalm = (len(dfsimlevMW),len(dfsimlevMW))\n",
    "    finalA = np.ones(finalm)\n",
    "    onematrix = pd.DataFrame(finalA)\n",
    "    dfsimlevMWone = onematrix.sub(dfsimlevMW)\n",
    "    finaldissimilaritymatrix = dfsimlevMWone.replace(1, 1000)\n",
    "    finaldissimilaritymatrix2 = finaldissimilaritymatrix.replace(float('inf'), 1000)\n",
    "    finaldissimilaritymatrix2numpy = finaldissimilaritymatrix2.to_numpy()\n",
    "    i_lower = np.tril_indices(len(tvlist), -1)\n",
    "    finaldissimilaritymatrix2numpy[i_lower] = finaldissimilaritymatrix2numpy.T[i_lower]\n",
    "    dffinaldissim = pd.DataFrame(finaldissimilaritymatrix2numpy)\n",
    "\n",
    "    clustering = AgglomerativeClustering(n_clusters = None, affinity='precomputed', linkage='complete', distance_threshold=param_cluster, compute_full_tree= True).fit(dffinaldissim)\n",
    "    labelsclust = clustering.labels_\n",
    "\n",
    "    originalm = (len(modelIDtrain),len(modelIDtrain))\n",
    "    originalA = np.zeros(originalm)\n",
    "    originalcorrect = pd.DataFrame(originalA, index=modelIDtrain, columns=modelIDtrain)\n",
    "    for i in range(0, len(modelIDtrain)):\n",
    "        for j in range(0, len(modelIDtrain)):\n",
    "            if modelIDtrain[i] == modelIDtrain[j]:\n",
    "                originalcorrect.iloc[i,j] = 1\n",
    "    originalcorrect.values[[np.arange(originalcorrect.shape[0])]*2] = 0\n",
    "\n",
    "    clusterdm = (len(modelIDtrain),len(modelIDtrain))\n",
    "    clusteredA = np.zeros(clusterdm)\n",
    "    clusteredmat = pd.DataFrame(clusteredA, index=modelIDtrain, columns=modelIDtrain)\n",
    "    check = pd.DataFrame(list(zip(labelsclust, modelIDtrain)))\n",
    "    for i in range(0, len(modelIDtrain)):\n",
    "        for j in range(0, len(modelIDtrain)):\n",
    "            if check[0][i] == check[0][j]:\n",
    "                clusteredmat.iloc[i,j] = 1\n",
    "    clusteredmat.values[[np.arange(clusteredmat.shape[0])]*2] = 0\n",
    "\n",
    "    ## Calculating the different measures \n",
    "    falsenegatives = 0\n",
    "    falsepositives = 0\n",
    "    truenegatives = 0\n",
    "    truepositives = 0\n",
    "\n",
    "    for i in range(0, len(originalcorrect)):\n",
    "        for j in range(0, len(originalcorrect)):\n",
    "            if j > i:\n",
    "                if  clusteredmat.iloc[i,j] == 0 and originalcorrect.iloc[i,j] == 0:\n",
    "                    truenegatives = truenegatives + 1\n",
    "                elif  clusteredmat.iloc[i,j] == 0 and originalcorrect.iloc[i,j] == 1:\n",
    "                    falsenegatives = falsenegatives + 1\n",
    "                elif  clusteredmat.iloc[i,j] == 1 and originalcorrect.iloc[i,j] == 0:\n",
    "                    falsepositives = falsepositives + 1\n",
    "                elif  clusteredmat.iloc[i,j] == 1 and originalcorrect.iloc[i,j] == 1:\n",
    "                    truepositives = truepositives + 1\n",
    "\n",
    "    f1measure = (truepositives/(truepositives+0.5*(falsenegatives+falsepositives)))\n",
    "    pairquality = (truepositives+falsepositives)/(numberofcomparisons) \n",
    "    paircompleteness = (truepositives)/(truepositives + falsenegatives)\n",
    "#     f1starmeasure = (2*pairquality*paircompleteness)/(pairquality+paircompleteness)\n",
    "#     f1starmeasure remvoed\n",
    "    return (fracofcomparisons, fracofcomparisons2, f1measure, truepositives, falsepositives, falsenegatives, truenegatives, pairquality, paircompleteness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performing the random grid search and making the final graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta =  [0.2, 0.3, 0.4]\n",
    "gamma = [0.8, 0.9]\n",
    "delta = [0.7, 0.8, 0.9]\n",
    "candidate_thresh = [0.15, 0.18, 0.2]\n",
    "modvar =  [1, 3 , 4, 5, 7, 14] \n",
    "a = [beta, gamma, delta, candidate_thresh]\n",
    "f1starlist = []\n",
    "f1list = []\n",
    "testvariables = []\n",
    "volgorde = rd.sample(list(itertools.product(*a)), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "beta =  [0.2, 0.3, 0.4]\n",
    "gamma = [0.8, 0.9]\n",
    "delta = [0.7, 0.8, 0.9]\n",
    "candidate_thresh = [0.15, 0.18, 0.2]\n",
    "# modvar =  [1, 3 , 4, 5, 7, 14] \n",
    "modvar = 14\n",
    "a = [beta, gamma, delta, candidate_thresh]\n",
    "f1list_fig4_14 = []\n",
    "fracofcomp1_fig4_14 = []\n",
    "fracofcomp2_fig4_14= []\n",
    "volgorde = rd.sample(list(itertools.product(*a)), 20)\n",
    "\n",
    "for j in range(0, 5):\n",
    "    for i in range(0, len(volgorde)):\n",
    "        print(i, \"beta:\" + str(volgorde[i][0]), \"gamma:\" + str(volgorde[i][1]), \"delta:\" + str(volgorde[i][2]), \"Threshold:\"+str(volgorde[i][3]),\"Modvar:\" + str(modvar))\n",
    "        newit = full_model(train[j], volgorde[i][0], volgorde[i][1], volgorde[i][2], modelID, modvar, volgorde[i][3])\n",
    "\n",
    "        newfracofcomp1_fig14 = newit[0]\n",
    "        newfracofcomp2_fig14 = newit[1]\n",
    "        newitf1 = newit[2]\n",
    "        f1list_fig4_5.append(newitf1)\n",
    "        fracofcomp1_fig4_14.append(newfracofcomp1_fig14)\n",
    "        fracofcomp2_fig4_14.append(newfracofcomp2_fig14)\n",
    "        print(newit) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "outcomes1 = []\n",
    "for j in range(0, 5):\n",
    "    outcome1_tuple = full_model(test[j],0.2,0.9,0.8, modelID, 1, 0.18)\n",
    "    outcomes1.append(outcome1_tuple)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "outcomes = []\n",
    "for j in range(0, 5):\n",
    "    outcome_tuple = full_model(test[j],0.2,0.9,0.9, modelID, 3, 0.15)\n",
    "    outcomes.append(outcome_tuple)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "outcomes4 = []\n",
    "for j in range(0, 5):\n",
    "    outcome_tuple4 = full_model(test[j],0.4,0.9,0.8, modelID, 4, 0.15)\n",
    "    outcomes4.append(outcome_tuple4)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "outcomes5 = []\n",
    "for j in range(0, 5):\n",
    "    outcome5_tuple = full_model(test[j],0.3,0.8,0.8, modelID, 5, 0.18)\n",
    "    outcomes5.append(outcome5_tuple)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "outcomes7 = []\n",
    "for j in range(0, 5):\n",
    "    outcome7_tuple = full_model(test[j],0.3,0.9,0.9, modelID, 7, 0.15)\n",
    "    outcomes7.append(outcome7_tuple)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "outcomes14 = []\n",
    "for j in range(0, 5):\n",
    "    outcome14_tuple = full_model(test[j],0.4,0.9,0.8, modelID, 14, 0.2)\n",
    "    outcomes14.append(outcome14_tuple)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgf1star1 = (outcomes1[0][2]+outcomes1[1][2]+outcomes1[2][2]+outcomes1[3][2]+outcomes1[4][2])/5\n",
    "avgf1star3 = (outcomes[0][2]+outcomes[1][2]+outcomes[2][2]+outcomes[3][2]+outcomes[4][2])/5\n",
    "avgf1star4 = (outcomes4[0][2]+outcomes4[1][2]+outcomes4[2][2]+outcomes4[3][2]+outcomes4[4][2])/5\n",
    "avgf1star5 = (outcomes5[0][2]+outcomes5[1][2]+outcomes5[2][2]+outcomes5[3][2]+outcomes5[4][2])/5\n",
    "avgf1star7 = (outcomes7[0][2]+outcomes7[1][2]+outcomes7[2][2]+outcomes7[3][2]+outcomes7[4][2])/5\n",
    "avgf1star14 = (outcomes14[0][2]+outcomes14[1][2]+outcomes14[2][2]+outcomes14[3][2]+outcomes14[4][2])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgcomp1 = (outcomes1[0][0]+outcomes1[1][0]+outcomes1[2][0]+outcomes1[3][0]+outcomes1[4][0])/5\n",
    "avgcomp3 = (outcomes[0][0]+outcomes[1][0]+outcomes[2][0]+outcomes[3][0]+outcomes[4][0])/5\n",
    "avgcomp4 = (outcomes4[0][0]+outcomes4[1][0]+outcomes4[2][0]+outcomes4[3][0]+outcomes4[4][0])/5\n",
    "avgcomp5 = (outcomes5[0][0]+outcomes5[1][0]+outcomes5[2][0]+outcomes5[3][0]+outcomes5[4][0])/5\n",
    "avgcomp7 = (outcomes7[0][0]+outcomes7[1][0]+outcomes7[2][0]+outcomes7[3][0]+outcomes7[4][0])/5\n",
    "avgcomp14 = (outcomes14[0][0]+outcomes14[1][0]+outcomes14[2][0]+outcomes14[3][0]+outcomes14[4][0])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listf1starssss = [avgf1star1,avgf1star3,avgf1star4,avgf1star5,avgf1star7,avgf1star14]\n",
    "listavgcompsss = [avgcomp1, avgcomp3, avgcomp4, avgcomp5, avgcomp7, avgcomp14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(avg_fracofcomp, avg_f1star)\n",
    "plt.plot(listavgcompsss, listf1starssss, 'k')\n",
    "plt.xlim(0,0.6)\n",
    "plt.ylim(0,0.4)\n",
    "plt.xlabel('Fraction of comparisons')\n",
    "plt.ylabel('$F_{1}$-measure')\n",
    "plt.savefig('fig4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
